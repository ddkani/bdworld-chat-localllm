# ğŸš€ LLM ì±„íŒ… ì‹œìŠ¤í…œ í”„ë¡œì íŠ¸ ê°œìš”

## ğŸ“‹ ëª©ì°¨
1. [í”„ë¡œì íŠ¸ ì†Œê°œ](#í”„ë¡œì íŠ¸-ì†Œê°œ)
2. [ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì „ì²´-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
3. [LLM í†µí•© êµ¬ì¡°](#llm-í†µí•©-êµ¬ì¡°)
4. [ë°±ì—”ë“œ êµ¬ì¡°](#ë°±ì—”ë“œ-êµ¬ì¡°)
5. [í”„ë¡ íŠ¸ì—”ë“œ êµ¬ì¡°](#í”„ë¡ íŠ¸ì—”ë“œ-êµ¬ì¡°)
6. [í†µì‹  í”Œë¡œìš°](#í†µì‹ -í”Œë¡œìš°)
7. [í•µì‹¬ ê¸°ëŠ¥](#í•µì‹¬-ê¸°ëŠ¥)

---

## ğŸ¯ í”„ë¡œì íŠ¸ ì†Œê°œ

### í”„ë¡œì íŠ¸ ê°œìš”
**bdworld-chat-codefair**ëŠ” ë¡œì»¬ì—ì„œ ì‹¤í–‰ë˜ëŠ” LLM(ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸)ì„ í™œìš©í•œ ì‹¤ì‹œê°„ ì±„íŒ… ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•
- ğŸ¤– **ë¡œì»¬ LLM ì‹¤í–‰**: Mistral 7B ëª¨ë¸ì„ ë¡œì»¬ì—ì„œ ì§ì ‘ ì‹¤í–‰
- ğŸ’¬ **ì‹¤ì‹œê°„ ì±„íŒ…**: WebSocketì„ í†µí•œ ì‹¤ì‹œê°„ ì–‘ë°©í–¥ í†µì‹ 
- ğŸ”’ **í”„ë¼ì´ë²„ì‹œ**: ëª¨ë“  ë°ì´í„°ê°€ ë¡œì»¬ì—ì„œ ì²˜ë¦¬
- ğŸ“± **ë°˜ì‘í˜• UI**: React ê¸°ë°˜ì˜ ëª¨ë˜í•œ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤
- ğŸ¨ **ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ**: ë³„ë„ì˜ ê´€ë¦¬ ì¸í„°í˜ì´ìŠ¤ ì œê³µ

### ê¸°ìˆ  ìŠ¤íƒ
```mermaid
graph TB
    subgraph "Frontend"
        REACT[React 18]
        TS[TypeScript]
        MUI[Material-UI]
        WS_CLIENT[WebSocket Client]
    end
    
    subgraph "Backend"
        DJANGO[Django 5.0]
        CHANNELS[Django Channels]
        DRF[Django REST Framework]
    end
    
    subgraph "AI/ML"
        MISTRAL[Mistral 7B]
        LLAMA_CPP[llama-cpp-python]
        CHROMA[ChromaDB]
    end
    
    subgraph "Database"
        SQLITE[SQLite]
        REDIS[Redis]
    end
```

## ğŸ—ï¸ ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ì‹œìŠ¤í…œ êµ¬ì„±ë„
```mermaid
graph TB
    subgraph "ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤"
        USER[ì‚¬ìš©ì]
        BROWSER[ì›¹ ë¸Œë¼ìš°ì €]
        USER --> BROWSER
    end
    
    subgraph "í”„ë¡ íŠ¸ì—”ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜"
        CHAT_UI[ì±„íŒ… UI<br/>:3001]
        ADMIN_UI[ê´€ë¦¬ì UI<br/>:3002]
        BROWSER --> CHAT_UI
        BROWSER --> ADMIN_UI
    end
    
    subgraph "API Gateway"
        HTTP[HTTP ìš”ì²­]
        WS[WebSocket ì—°ê²°]
        CHAT_UI --> HTTP
        CHAT_UI --> WS
        ADMIN_UI --> HTTP
    end
    
    subgraph "ë°±ì—”ë“œ ì„œë²„ [:8000]"
        DJANGO_APP[Django Application]
        ASGI[ASGI Server<br/>Daphne]
        WSGI[WSGI Server]
        
        HTTP --> WSGI
        WS --> ASGI
        WSGI --> DJANGO_APP
        ASGI --> DJANGO_APP
    end
    
    subgraph "LLM ì²˜ë¦¬"
        LLM_SERVICE[LLM Service]
        MODEL[Mistral 7B<br/>GGUF Format]
        DJANGO_APP --> LLM_SERVICE
        LLM_SERVICE --> MODEL
    end
    
    subgraph "ë°ì´í„° ì €ì¥ì†Œ"
        DB[(SQLite)]
        VECTOR[(ChromaDB)]
        CACHE[(Redis)]
        DJANGO_APP --> DB
        LLM_SERVICE --> VECTOR
        ASGI --> CACHE
    end
    
    style USER fill:#e1f5fe
    style CHAT_UI fill:#c8e6c9
    style ADMIN_UI fill:#c8e6c9
    style DJANGO_APP fill:#fff3e0
    style LLM_SERVICE fill:#f3e5f5
    style MODEL fill:#f3e5f5
```

### ë ˆì´ì–´ë³„ ì±…ì„

| ë ˆì´ì–´ | êµ¬ì„± ìš”ì†Œ | ì±…ì„ |
|--------|-----------|------|
| **Presentation** | React UI | ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤, ì…ë ¥ ì²˜ë¦¬, ê²°ê³¼ í‘œì‹œ |
| **API Gateway** | HTTP/WebSocket | ìš”ì²­ ë¼ìš°íŒ…, í”„ë¡œí† ì½œ ë³€í™˜ |
| **Application** | Django | ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§, ì¸ì¦, ì„¸ì…˜ ê´€ë¦¬ |
| **Service** | LLM Service | AI ëª¨ë¸ ì‹¤í–‰, í…ìŠ¤íŠ¸ ìƒì„± |
| **Data** | DB/Cache | ë°ì´í„° ì˜ì†ì„±, ìºì‹± |

## ğŸ¤– LLM í†µí•© êµ¬ì¡°

### LLM ì‹¤í–‰ í”Œë¡œìš°
```mermaid
sequenceDiagram
    participant U as ì‚¬ìš©ì
    participant F as Frontend
    participant W as WebSocket
    participant B as Backend
    participant L as LLM Service
    participant M as Mistral Model
    participant D as Database
    
    U->>F: ë©”ì‹œì§€ ì…ë ¥
    F->>W: WebSocket ì „ì†¡
    W->>B: ë©”ì‹œì§€ ìˆ˜ì‹ 
    B->>D: ë©”ì‹œì§€ ì €ì¥
    B->>L: í…ìŠ¤íŠ¸ ìƒì„± ìš”ì²­
    
    L->>L: í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    Note over L: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ +<br/>ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ +<br/>ì‚¬ìš©ì ë©”ì‹œì§€
    
    L->>M: ëª¨ë¸ ì‹¤í–‰
    
    loop ìŠ¤íŠ¸ë¦¬ë° ìƒì„±
        M->>L: í† í° ìƒì„±
        L->>B: ì²­í¬ ì „ë‹¬
        B->>W: ìŠ¤íŠ¸ë¦¼ ì „ì†¡
        W->>F: ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
        F->>U: í™”ë©´ í‘œì‹œ
    end
    
    L->>B: ìƒì„± ì™„ë£Œ
    B->>D: AI ì‘ë‹µ ì €ì¥
    B->>W: ì™„ë£Œ ì‹ í˜¸
    W->>F: ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
```

### LLM ì„œë¹„ìŠ¤ êµ¬ì¡°
```python
# backend/llm/llm_service.py êµ¬ì¡°

class LLMService:
    """LLM í†µí•© ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        # 1. ëª¨ë¸ ë¡œë“œ
        self.model = self._load_model()
        
        # 2. ì„¤ì • ì´ˆê¸°í™”
        self.config = {
            'max_tokens': 512,
            'temperature': 0.7,
            'context_length': 4096
        }
        
        # 3. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.templates = PromptTemplates()
    
    def _load_model(self):
        """Mistral 7B ëª¨ë¸ ë¡œë“œ"""
        return Llama(
            model_path="models/mistral-7b.gguf",
            n_ctx=4096,        # ì»¨í…ìŠ¤íŠ¸ í¬ê¸°
            n_gpu_layers=32,   # GPU ë ˆì´ì–´
            n_threads=8        # CPU ìŠ¤ë ˆë“œ
        )
    
    async def generate_stream(self, prompt, context):
        """ìŠ¤íŠ¸ë¦¬ë° í…ìŠ¤íŠ¸ ìƒì„±"""
        # 1. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        full_prompt = self.templates.build(prompt, context)
        
        # 2. í† í° ìˆ˜ í™•ì¸
        if self.count_tokens(full_prompt) > 3500:
            context = self.truncate_context(context)
            full_prompt = self.templates.build(prompt, context)
        
        # 3. ìŠ¤íŠ¸ë¦¬ë° ìƒì„±
        for token in self.model(full_prompt, stream=True):
            yield token['choices'][0]['text']
```

### ëª¨ë¸ ìµœì í™” ì „ëµ
```mermaid
graph LR
    subgraph "ì›ë³¸ ëª¨ë¸"
        ORIG[Mistral 7B<br/>28GB FP32]
    end
    
    subgraph "ì–‘ìí™”"
        QUANT[GGUF Q4_K_M<br/>4.3GB]
    end
    
    subgraph "ì‹¤í–‰ ìµœì í™”"
        CPU[CPU ì‹¤í–‰<br/>llama.cpp]
        GPU[GPU ê°€ì†<br/>CUDA/Metal]
    end
    
    subgraph "ë©”ëª¨ë¦¬ ê´€ë¦¬"
        CACHE[KV Cache]
        BATCH[ë°°ì¹˜ ì²˜ë¦¬]
    end
    
    ORIG -->|ì–‘ìí™”| QUANT
    QUANT --> CPU
    QUANT --> GPU
    CPU --> CACHE
    GPU --> BATCH
```

## ğŸ”§ ë°±ì—”ë“œ êµ¬ì¡°

### Django ì• í”Œë¦¬ì¼€ì´ì…˜ êµ¬ì¡°
```mermaid
graph TB
    subgraph "Django Project"
        SETTINGS[settings.py<br/>ì „ì—­ ì„¤ì •]
        URLS[urls.py<br/>URL ë¼ìš°íŒ…]
        ASGI_PY[asgi.py<br/>ë¹„ë™ê¸° ì„œë²„]
        WSGI_PY[wsgi.py<br/>ë™ê¸° ì„œë²„]
    end
    
    subgraph "Chat App"
        MODELS[models.py<br/>ë°ì´í„° ëª¨ë¸]
        VIEWS[views.py<br/>API ë·°]
        SERIAL[serializers.py<br/>ì§ë ¬í™”]
        CONSUMERS[consumers.py<br/>WebSocket]
        ROUTING[routing.py<br/>WS ë¼ìš°íŒ…]
    end
    
    subgraph "LLM App"
        LLM_SVC[llm_service.py<br/>AI ì„œë¹„ìŠ¤]
        LLM_MODELS[models.py<br/>AI ëª¨ë¸]
        LLM_VIEWS[views.py<br/>AI API]
    end
    
    URLS --> VIEWS
    ASGI_PY --> ROUTING
    ROUTING --> CONSUMERS
    VIEWS --> SERIAL
    SERIAL --> MODELS
    CONSUMERS --> LLM_SVC
```

### API ì—”ë“œí¬ì¸íŠ¸ êµ¬ì¡°
```python
# backend/chat_project/urls.py

urlpatterns = [
    # ì¸ì¦ API
    path('api/auth/register/', RegisterView.as_view()),
    path('api/auth/login/', LoginView.as_view()),
    path('api/auth/logout/', LogoutView.as_view()),
    
    # ì±„íŒ… ì„¸ì…˜ API
    path('api/sessions/', ChatSessionViewSet.as_view({
        'get': 'list',      # ì„¸ì…˜ ëª©ë¡
        'post': 'create'    # ìƒˆ ì„¸ì…˜
    })),
    path('api/sessions/<int:pk>/', ChatSessionViewSet.as_view({
        'get': 'retrieve',   # ì„¸ì…˜ ìƒì„¸
        'put': 'update',     # ì„¸ì…˜ ìˆ˜ì •
        'delete': 'destroy'  # ì„¸ì…˜ ì‚­ì œ
    })),
    
    # ë©”ì‹œì§€ API
    path('api/sessions/<int:session_id>/messages/', MessageViewSet.as_view({
        'get': 'list',      # ë©”ì‹œì§€ ëª©ë¡
        'post': 'create'    # ë©”ì‹œì§€ ì „ì†¡
    })),
    
    # LLM API
    path('api/llm/generate/', LLMGenerateView.as_view()),
    path('api/llm/models/', LLMModelsView.as_view()),
]

# WebSocket ë¼ìš°íŒ…
websocket_urlpatterns = [
    path('ws/chat/<int:session_id>/', ChatConsumer.as_asgi()),
]
```

### ë°ì´í„° ëª¨ë¸ ê´€ê³„
```mermaid
erDiagram
    User ||--o{ ChatSession : creates
    ChatSession ||--o{ Message : contains
    ChatSession ||--|| SessionConfig : has
    Message ||--|| MessageMetadata : has
    
    User {
        int id PK
        string username
        string email
        datetime created_at
    }
    
    ChatSession {
        int id PK
        int user_id FK
        string title
        datetime created_at
        datetime updated_at
    }
    
    Message {
        int id PK
        int session_id FK
        text content
        boolean is_user
        datetime timestamp
        int token_count
        float processing_time
    }
    
    SessionConfig {
        int id PK
        int session_id FK
        float temperature
        int max_tokens
        string system_prompt
    }
    
    MessageMetadata {
        int id PK
        int message_id FK
        json prompt_template
        json model_params
        string model_version
    }
```

## ğŸ’» í”„ë¡ íŠ¸ì—”ë“œ êµ¬ì¡°

### React ì»´í¬ë„ŒíŠ¸ ê³„ì¸µ
```mermaid
graph TB
    subgraph "App Root"
        APP[App.tsx]
    end
    
    subgraph "Providers"
        AUTH_PROVIDER[AuthProvider]
        THEME_PROVIDER[ThemeProvider]
        WS_PROVIDER[WebSocketProvider]
    end
    
    subgraph "Pages"
        LOGIN[LoginPage]
        CHAT[ChatPage]
        ADMIN[AdminPage]
    end
    
    subgraph "Containers"
        CHAT_CONTAINER[ChatContainer]
        SESSION_LIST[SessionList]
        USER_PROFILE[UserProfile]
    end
    
    subgraph "Components"
        MESSAGE_LIST[MessageList]
        MESSAGE_ITEM[MessageItem]
        INPUT_BOX[InputBox]
        SIDEBAR[Sidebar]
    end
    
    subgraph "UI Components"
        BUTTON[Button]
        CARD[Card]
        DIALOG[Dialog]
        LOADING[LoadingSpinner]
    end
    
    APP --> AUTH_PROVIDER
    AUTH_PROVIDER --> THEME_PROVIDER
    THEME_PROVIDER --> WS_PROVIDER
    WS_PROVIDER --> CHAT
    
    CHAT --> CHAT_CONTAINER
    CHAT --> SESSION_LIST
    
    CHAT_CONTAINER --> MESSAGE_LIST
    CHAT_CONTAINER --> INPUT_BOX
    
    MESSAGE_LIST --> MESSAGE_ITEM
    MESSAGE_ITEM --> CARD
    INPUT_BOX --> BUTTON
```

### ìƒíƒœ ê´€ë¦¬ êµ¬ì¡°
```typescript
// frontend-chat/src/store/structure.ts

interface AppState {
    // ì¸ì¦ ìƒíƒœ
    auth: {
        user: User | null;
        token: string | null;
        isAuthenticated: boolean;
    };
    
    // ì±„íŒ… ìƒíƒœ
    chat: {
        sessions: ChatSession[];
        currentSession: ChatSession | null;
        messages: Map<number, Message[]>;
        isLoading: boolean;
    };
    
    // WebSocket ìƒíƒœ
    websocket: {
        connection: WebSocket | null;
        status: 'connecting' | 'connected' | 'disconnected';
        reconnectAttempts: number;
    };
    
    // UI ìƒíƒœ
    ui: {
        theme: 'light' | 'dark';
        sidebarOpen: boolean;
        notifications: Notification[];
    };
}
```

### ì„œë¹„ìŠ¤ ë ˆì´ì–´
```typescript
// frontend-chat/src/services/structure.ts

class APIService {
    // HTTP í†µì‹ 
    async get<T>(url: string): Promise<T>
    async post<T>(url: string, data: any): Promise<T>
    async put<T>(url: string, data: any): Promise<T>
    async delete(url: string): Promise<void>
}

class WebSocketService {
    // WebSocket í†µì‹ 
    connect(sessionId: number): void
    disconnect(): void
    send(message: any): void
    on(event: string, callback: Function): void
    off(event: string, callback: Function): void
}

class ChatService {
    // ì±„íŒ… ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
    async createSession(title: string): Promise<ChatSession>
    async loadSessions(): Promise<ChatSession[]>
    async sendMessage(content: string): Promise<void>
    subscribeToMessages(callback: Function): void
}
```

## ğŸ”„ í†µì‹  í”Œë¡œìš°

### HTTP í†µì‹  í”Œë¡œìš°
```mermaid
sequenceDiagram
    participant C as Client
    participant API as API Service
    participant S as Django Server
    participant DB as Database
    
    Note over C,DB: ì„¸ì…˜ ìƒì„± í”Œë¡œìš°
    
    C->>API: createSession(title)
    API->>API: í† í° ì¶”ê°€
    API->>S: POST /api/sessions/
    S->>S: ì¸ì¦ í™•ì¸
    S->>DB: ì„¸ì…˜ ì €ì¥
    DB->>S: ì„¸ì…˜ ID
    S->>API: 201 Created + ì„¸ì…˜ ë°ì´í„°
    API->>C: ChatSession ê°ì²´
    
    Note over C,DB: ë©”ì‹œì§€ ì¡°íšŒ í”Œë¡œìš°
    
    C->>API: loadMessages(sessionId)
    API->>S: GET /api/sessions/{id}/messages/
    S->>DB: ë©”ì‹œì§€ ì¿¼ë¦¬
    DB->>S: ë©”ì‹œì§€ ëª©ë¡
    S->>API: 200 OK + ë©”ì‹œì§€ ë°°ì—´
    API->>C: Message[] ë°°ì—´
```

### WebSocket í†µì‹  í”Œë¡œìš°
```mermaid
sequenceDiagram
    participant C as Client
    participant WS as WebSocket
    participant CH as Channels
    participant CS as Consumer
    participant LLM as LLM Service
    
    Note over C,LLM: WebSocket ì—°ê²° ë° ë©”ì‹œì§€ ì „ì†¡
    
    C->>WS: new WebSocket(url)
    WS->>CH: ì—°ê²° ìš”ì²­
    CH->>CS: connect()
    CS->>CS: ì¸ì¦ í™•ì¸
    CS->>CH: accept()
    CH->>WS: ì—°ê²° ìˆ˜ë¦½
    WS->>C: onopen
    
    C->>WS: send({type: 'chat_message', message: 'Hello'})
    WS->>CH: ë©”ì‹œì§€ ë¼ìš°íŒ…
    CH->>CS: receive_json()
    
    CS->>CS: ë©”ì‹œì§€ ì €ì¥
    CS->>LLM: generate_stream(message)
    
    loop ìŠ¤íŠ¸ë¦¬ë°
        LLM->>CS: yield chunk
        CS->>CH: send_json({type: 'ai_chunk', chunk})
        CH->>WS: í”„ë ˆì„ ì „ì†¡
        WS->>C: onmessage(chunk)
    end
    
    CS->>CH: send_json({type: 'ai_complete'})
    CH->>WS: ì™„ë£Œ ì‹ í˜¸
    WS->>C: onmessage(complete)
```

### ì—ëŸ¬ ì²˜ë¦¬ í”Œë¡œìš°
```mermaid
graph TB
    subgraph "Client Error Handling"
        C_ERR[ì—ëŸ¬ ë°œìƒ]
        C_CATCH[try-catch]
        C_RETRY[ì¬ì‹œë„ ë¡œì§]
        C_NOTIFY[ì‚¬ìš©ì ì•Œë¦¼]
    end
    
    subgraph "Network Error"
        NET_TIMEOUT[íƒ€ì„ì•„ì›ƒ]
        NET_DISCONNECT[ì—°ê²° ëŠê¹€]
        NET_RECONNECT[ìë™ ì¬ì—°ê²°]
    end
    
    subgraph "Server Error"
        S_400[400 Bad Request]
        S_401[401 Unauthorized]
        S_500[500 Server Error]
    end
    
    subgraph "LLM Error"
        LLM_OOM[ë©”ëª¨ë¦¬ ë¶€ì¡±]
        LLM_TIMEOUT[ìƒì„± íƒ€ì„ì•„ì›ƒ]
        LLM_FALLBACK[í´ë°± ì²˜ë¦¬]
    end
    
    C_ERR --> C_CATCH
    C_CATCH --> C_RETRY
    C_RETRY --> C_NOTIFY
    
    NET_TIMEOUT --> NET_RECONNECT
    NET_DISCONNECT --> NET_RECONNECT
    
    S_401 --> C_NOTIFY
    S_500 --> C_RETRY
    
    LLM_OOM --> LLM_FALLBACK
    LLM_TIMEOUT --> LLM_FALLBACK
```

## ğŸ¨ í•µì‹¬ ê¸°ëŠ¥

### 1. ì‹¤ì‹œê°„ ì±„íŒ…
```mermaid
graph LR
    subgraph "ê¸°ëŠ¥"
        RT_MSG[ì‹¤ì‹œê°„ ë©”ì‹œì§€]
        TYPING[íƒ€ì´í•‘ í‘œì‹œ]
        PRESENCE[ì˜¨ë¼ì¸ ìƒíƒœ]
        NOTIF[ì•Œë¦¼]
    end
    
    subgraph "ê¸°ìˆ "
        WS_CONN[WebSocket]
        CHANNELS[Django Channels]
        REDIS_PS[Redis Pub/Sub]
    end
    
    RT_MSG --> WS_CONN
    TYPING --> WS_CONN
    PRESENCE --> REDIS_PS
    NOTIF --> CHANNELS
```

### 2. AI ì‘ë‹µ ìƒì„±
```mermaid
graph TB
    subgraph "ì…ë ¥ ì²˜ë¦¬"
        USER_INPUT[ì‚¬ìš©ì ì…ë ¥]
        VALIDATE[ê²€ì¦]
        PREPROCESS[ì „ì²˜ë¦¬]
    end
    
    subgraph "AI ì²˜ë¦¬"
        CONTEXT[ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±]
        PROMPT[í”„ë¡¬í”„íŠ¸ ìƒì„±]
        GENERATE[í…ìŠ¤íŠ¸ ìƒì„±]
        STREAM[ìŠ¤íŠ¸ë¦¬ë°]
    end
    
    subgraph "ì¶œë ¥ ì²˜ë¦¬"
        FORMAT[í¬ë§·íŒ…]
        MARKDOWN[ë§ˆí¬ë‹¤ìš´ ë Œë”ë§]
        CODE_HL[ì½”ë“œ í•˜ì´ë¼ì´íŒ…]
    end
    
    USER_INPUT --> VALIDATE
    VALIDATE --> PREPROCESS
    PREPROCESS --> CONTEXT
    CONTEXT --> PROMPT
    PROMPT --> GENERATE
    GENERATE --> STREAM
    STREAM --> FORMAT
    FORMAT --> MARKDOWN
    FORMAT --> CODE_HL
```

### 3. ì„¸ì…˜ ê´€ë¦¬
```typescript
// ì„¸ì…˜ ê´€ë¦¬ ê¸°ëŠ¥
interface SessionManager {
    // ì„¸ì…˜ ìƒì„±/ì‚­ì œ
    createSession(title: string): Promise<Session>
    deleteSession(id: number): Promise<void>
    
    // ì„¸ì…˜ ì „í™˜
    switchSession(id: number): void
    getCurrentSession(): Session | null
    
    // ì„¸ì…˜ ë‚´ë³´ë‚´ê¸°/ê°€ì ¸ì˜¤ê¸°
    exportSession(id: number): Promise<ExportData>
    importSession(data: ExportData): Promise<Session>
    
    // ì„¸ì…˜ ê²€ìƒ‰
    searchSessions(query: string): Session[]
    getRecentSessions(limit: number): Session[]
}
```

### 4. ì‚¬ìš©ì ê´€ë¦¬
```python
# ì‚¬ìš©ì ê´€ë¦¬ ê¸°ëŠ¥
class UserManager:
    def register(self, username: str, email: str) -> User
    def login(self, username: str) -> AuthToken
    def logout(self, token: str) -> None
    
    # í”„ë¡œí•„ ê´€ë¦¬
    def get_profile(self, user_id: int) -> UserProfile
    def update_profile(self, user_id: int, data: dict) -> UserProfile
    
    # ì‚¬ìš© í†µê³„
    def get_usage_stats(self, user_id: int) -> UsageStats
    def get_message_history(self, user_id: int) -> List[Message]
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### ë°±ì—”ë“œ ìµœì í™”
```python
# 1. ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”
sessions = ChatSession.objects.select_related('user') \
                              .prefetch_related('messages') \
                              .filter(user=request.user)

# 2. ìºì‹± ì „ëµ
from django.core.cache import cache

def get_session_with_cache(session_id):
    cache_key = f'session_{session_id}'
    session = cache.get(cache_key)
    
    if session is None:
        session = ChatSession.objects.get(id=session_id)
        cache.set(cache_key, session, 300)  # 5ë¶„ ìºì‹±
    
    return session

# 3. ë¹„ë™ê¸° ì²˜ë¦¬
async def process_message_async(message):
    # ë¹„ë™ê¸° DB ì¿¼ë¦¬
    session = await ChatSession.objects.aget(id=message.session_id)
    
    # ë¹„ë™ê¸° LLM ì²˜ë¦¬
    async for chunk in llm_service.generate_async(message.content):
        await send_to_client(chunk)
```

### í”„ë¡ íŠ¸ì—”ë“œ ìµœì í™”
```typescript
// 1. React ë©”ëª¨ì´ì œì´ì…˜
const MessageList = React.memo(({ messages }) => {
    return messages.map(msg => <MessageItem key={msg.id} {...msg} />)
}, (prev, next) => prev.messages.length === next.messages.length);

// 2. ê°€ìƒ ìŠ¤í¬ë¡¤ë§
import { FixedSizeList } from 'react-window';

const VirtualMessageList = ({ messages }) => (
    <FixedSizeList
        height={600}
        itemCount={messages.length}
        itemSize={80}
        width="100%"
    >
        {({ index, style }) => (
            <div style={style}>
                <MessageItem {...messages[index]} />
            </div>
        )}
    </FixedSizeList>
);

// 3. ë””ë°”ìš´ì‹±
const debouncedSearch = useMemo(
    () => debounce((query: string) => {
        searchSessions(query);
    }, 300),
    []
);
```

### LLM ìµœì í™”
```python
# 1. ëª¨ë¸ ìºì‹±
class ModelCache:
    _instance = None
    _model = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._model = Llama(model_path="model.gguf")
        return cls._instance

# 2. ë°°ì¹˜ ì²˜ë¦¬
def batch_generate(prompts: List[str]):
    results = []
    for batch in chunks(prompts, batch_size=4):
        batch_results = model.generate_batch(batch)
        results.extend(batch_results)
    return results

# 3. KV ìºì‹œ ê´€ë¦¬
model = Llama(
    model_path="model.gguf",
    n_ctx=4096,
    use_mmap=True,      # ë©”ëª¨ë¦¬ ë§¤í•‘
    use_mlock=True,     # ë©”ëª¨ë¦¬ ê³ ì •
    n_batch=512,        # ë°°ì¹˜ í¬ê¸°
    n_threads=8         # ë³‘ë ¬ ì²˜ë¦¬
)
```

## ğŸ”’ ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### ì¸ì¦ ë° ê¶Œí•œ
```mermaid
graph TB
    subgraph "ì¸ì¦ í”Œë¡œìš°"
        LOGIN[ë¡œê·¸ì¸]
        TOKEN[í† í° ë°œê¸‰]
        VERIFY[í† í° ê²€ì¦]
        ACCESS[ì ‘ê·¼ í—ˆìš©]
    end
    
    subgraph "ë³´ì•ˆ ê³„ì¸µ"
        CORS[CORS ì„¤ì •]
        CSRF[CSRF ë³´í˜¸]
        XSS[XSS ë°©ì§€]
        SQL_INJ[SQL Injection ë°©ì§€]
    end
    
    subgraph "ë°ì´í„° ë³´í˜¸"
        ENCRYPT[ì•”í˜¸í™”]
        HASH[í•´ì‹±]
        SANITIZE[ì‚´ê· ì²˜ë¦¬]
    end
    
    LOGIN --> TOKEN
    TOKEN --> VERIFY
    VERIFY --> ACCESS
    
    ACCESS --> CORS
    ACCESS --> CSRF
    ACCESS --> XSS
    ACCESS --> SQL_INJ
    
    ENCRYPT --> HASH
    HASH --> SANITIZE
```

## ğŸ“š ì°¸ê³  ìë£Œ

### í”„ë¡œì íŠ¸ ë¬¸ì„œ
- [ì›¹ ê°œë°œ ê¸°ì´ˆ](./01-ì›¹ê°œë°œ-ê¸°ì´ˆê°œë….md)
- [ë„¤íŠ¸ì›Œí¬ì™€ í†µì‹ ](./02-ë„¤íŠ¸ì›Œí¬ì™€-í†µì‹ -ê¸°ì´ˆ.md)
- [í”„ë¡œì íŠ¸ êµ¬ì¡° ì‹¬í™”](./08-í”„ë¡œì íŠ¸-êµ¬ì¡°-ì‹¬í™”.md)
- [LLM ë¡œì»¬ ì‹¤í–‰](./10-LLM-ë¡œì»¬ì‹¤í–‰-ìƒì„¸.md)

### ì™¸ë¶€ ì°¸ê³  ìë£Œ
- [Django ê³µì‹ ë¬¸ì„œ](https://docs.djangoproject.com/)
- [React ê³µì‹ ë¬¸ì„œ](https://react.dev/)
- [WebSocket MDN](https://developer.mozilla.org/ko/docs/Web/API/WebSocket)
- [llama.cpp GitHub](https://github.com/ggerganov/llama.cpp)

## ğŸ¯ í•µì‹¬ ì •ë¦¬

1. **í†µí•© ì•„í‚¤í…ì²˜**: LLM + ë°±ì—”ë“œ + í”„ë¡ íŠ¸ì—”ë“œê°€ ìœ ê¸°ì ìœ¼ë¡œ ì—°ê²°
2. **ì‹¤ì‹œê°„ í†µì‹ **: WebSocketì„ í†µí•œ ì–‘ë°©í–¥ ì‹¤ì‹œê°„ í†µì‹ 
3. **ë¡œì»¬ AI**: í”„ë¼ì´ë²„ì‹œë¥¼ ë³´ì¥í•˜ëŠ” ë¡œì»¬ LLM ì‹¤í–‰
4. **í™•ì¥ ê°€ëŠ¥**: ëª¨ë“ˆí™”ëœ êµ¬ì¡°ë¡œ ê¸°ëŠ¥ ì¶”ê°€ ìš©ì´
5. **ìµœì í™”**: ê° ë ˆì´ì–´ë³„ ì„±ëŠ¥ ìµœì í™” ì ìš©

---

ë‹¤ìŒ: [01-ì›¹ê°œë°œ-ê¸°ì´ˆê°œë….md](./01-ì›¹ê°œë°œ-ê¸°ì´ˆê°œë….md)